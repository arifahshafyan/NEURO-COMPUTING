{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "dataset = pd.read_csv('data/AND.csv')\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "print(clf.score(data,label))\n",
    "print(clf.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND Dataset\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Dataset AND\n",
    "data_and = {'input1': [0, 0, 1, 1],\n",
    "            'input2': [0, 1, 0, 1],\n",
    "            'label': [0, 0, 0, 1]}\n",
    "dataset_and = pd.DataFrame(data_and)\n",
    "\n",
    "# Split data dan label\n",
    "data = dataset_and.iloc[:, :-1]\n",
    "label = dataset_and.iloc[:, -1]\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf_and = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_and.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"AND Dataset\")\n",
    "print(f\"Accuracy: {clf_and.score(data, label)}\")\n",
    "print(f\"Predictions: {clf_and.predict(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  Y\n",
       "0   0   0  0\n",
       "1   0   1  0\n",
       "2   1   0  0\n",
       "3   1   1  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Assignment #1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Lakukan Single Perceptron untuk data AND, OR, XOR, digit,iris, ruspini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  Y\n",
      "0   0   0  0\n",
      "1   0   1  0\n",
      "2   1   0  0\n",
      "3   1   1  1\n",
      "AND Dataset\n",
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/AND.csv')\n",
    "# Split data dan label\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(dataset)  \n",
    "print(\"AND Dataset\")\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  Y\n",
      "0   0   0  0\n",
      "1   0   1  1\n",
      "2   1   0  1\n",
      "3   1   1  1\n",
      "OR Dataset\n",
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/OR.csv')\n",
    "# Split data dan label\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(dataset)\n",
    "print(\"OR Dataset\")\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  Y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X1  X2  Y\n",
      "0   0   0  0\n",
      "1   0   1  1\n",
      "2   1   0  1\n",
      "3   1   1  0\n",
      "XOR Dataset\n",
      "\n",
      "Accuracy: 0.5\n",
      "Predictions: [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/XOR.csv')\n",
    "# Split data dan label\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(dataset)\n",
    "print(\"XOR Dataset\")\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  Y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIGIT Dataset\n",
      "    a1  a2  a3  a4  a5  a6  a7  a8  a9  a10  ...  a92  a93  a94  a95  a96  \\\n",
      "77   0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
      "78   0   0   0   1   1   1   1   1   0    0  ...    0    0    1    1    1   \n",
      "79   0   0   0   1   1   1   0   0   0    0  ...    0    0    0    0    0   \n",
      "\n",
      "    a97  a98  a99  a100  Class  \n",
      "77    1    1    1     0      9  \n",
      "78    1    1    0     0      9  \n",
      "79    0    0    0     0      9  \n",
      "\n",
      "[3 rows x 101 columns]\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 4 4 4 4 4\n",
      " 4 4 4 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 9 9\n",
      " 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/digit.csv')\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"DIGIT Dataset\")\n",
    "print(dataset.tail(3))\n",
    "print(f\"Accuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>...</th>\n",
       "      <th>a92</th>\n",
       "      <th>a93</th>\n",
       "      <th>a94</th>\n",
       "      <th>a95</th>\n",
       "      <th>a96</th>\n",
       "      <th>a97</th>\n",
       "      <th>a98</th>\n",
       "      <th>a99</th>\n",
       "      <th>a100</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a1  a2  a3  a4  a5  a6  a7  a8  a9  a10  ...  a92  a93  a94  a95  a96  \\\n",
       "0    0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "1    0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "2    0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "3    0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "4    0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "75   0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "76   0   0   0   1   1   1   1   0   0    0  ...    0    0    0    0    0   \n",
       "77   0   0   0   0   0   0   0   0   0    0  ...    0    0    0    0    0   \n",
       "78   0   0   0   1   1   1   1   1   0    0  ...    0    0    1    1    1   \n",
       "79   0   0   0   1   1   1   0   0   0    0  ...    0    0    0    0    0   \n",
       "\n",
       "    a97  a98  a99  a100  Class  \n",
       "0     0    0    0     0      0  \n",
       "1     0    1    1     0      0  \n",
       "2     0    0    0     0      0  \n",
       "3     0    0    0     0      0  \n",
       "4     0    0    0     0      0  \n",
       "..  ...  ...  ...   ...    ...  \n",
       "75    1    0    0     0      9  \n",
       "76    0    0    0     0      9  \n",
       "77    1    1    1     0      9  \n",
       "78    1    1    0     0      9  \n",
       "79    0    0    0     0      9  \n",
       "\n",
       "[80 rows x 101 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Dataset\n",
      "     5.1  3.5  1.4   .2  0\n",
      "146  6.5  3.0  5.2  2.0  1\n",
      "147  6.2  3.4  5.4  2.3  1\n",
      "148  5.9  3.0  5.1  1.8  1\n",
      "\n",
      "Accuracy: 0.8187919463087249\n",
      "Predictions: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      " -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0\n",
      "  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1  1 -1  1  1  1  1 -1 -1  1 -1 -1 -1  1  1  1 -1  1  1 -1  1\n",
      "  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1  1  1  1\n",
      "  1 -1 -1  1  1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/iris.csv')\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"IRIS Dataset\")\n",
    "print(dataset.tail(3))\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Dataset\n",
      "Accuracy: 0.92\n",
      "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 1 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standarisasi fitur\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf_iris = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_iris.fit(X_standardized, y)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"IRIS Dataset\")\n",
    "print(f\"Accuracy: {clf_iris.score(X_standardized, y)}\")\n",
    "print(f\"Predictions: {clf_iris.predict(X_standardized)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n  Mathematical Statistics\" (John Wiley, NY, 1950).\\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n  Structure and Classification Rule for Recognition in Partially Exposed\\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n  on Information Theory, May 1972, 431-433.\\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n  conceptual clustering system finds 3 classes in the data.\\n- Many, many more ...\\n\\n|details-end|\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>.2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.1  3.5  1.4   .2  0\n",
       "0    4.9  3.0  1.4  0.2  0\n",
       "1    4.7  3.2  1.3  0.2  0\n",
       "2    4.6  3.1  1.5  0.2  0\n",
       "3    5.0  3.6  1.4  0.2  0\n",
       "4    5.4  3.9  1.7  0.4  0\n",
       "..   ...  ...  ...  ... ..\n",
       "144  6.7  3.0  5.2  2.3  1\n",
       "145  6.3  2.5  5.0  1.9  1\n",
       "146  6.5  3.0  5.2  2.0  1\n",
       "147  6.2  3.4  5.4  2.3  1\n",
       "148  5.9  3.0  5.1  1.8  1\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSPINI Dataset\n",
      "     #   X   Y  CLASS\n",
      "72  73  76  27      4\n",
      "73  74  72  31      4\n",
      "74  75  64  30      4\n",
      "\n",
      "Accuracy: 0.72\n",
      "Predictions: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/ruspini.csv')\n",
    "data = dataset.iloc[:,0:-1]\n",
    "label = dataset.iloc[:,-1]\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(data, label)\n",
    "\n",
    "print(\"RUSPINI Dataset\")\n",
    "print(dataset.tail(3))\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruspini-like Dataset\n",
      "Accuracy: 0.82\n",
      "Predictions: [1 3 0 0 0 1 2 3 3 3 3 3 3 3 3 1 1 1 2 1 1 3 2 1 3 2 0 0 0 1 1 3 1 1 2 1 3\n",
      " 1 3 2 3 2 2 2 2 3 1 2 1 2 3 1 2 2 2 3 3 1 1 3 3 1 1 0 1 3 2 2 1 0 3 1 0 3\n",
      " 0 0 1 2 1 1 1 3 2 2 1 2 1 1 0 0 0 2 2 2 2 3 3 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate dataset mirip Ruspini\n",
    "X_ruspini, y_ruspini = make_blobs(n_samples=100, centers=4, random_state=0, cluster_std=1.0)\n",
    "\n",
    "# Membuat model Perceptron\n",
    "clf_ruspini = Perceptron(tol=1e-3, random_state=0)\n",
    "clf_ruspini.fit(X_ruspini, y_ruspini)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"Ruspini-like Dataset\")\n",
    "print(f\"Accuracy: {clf_ruspini.score(X_ruspini, y_ruspini)}\")\n",
    "print(f\"Predictions: {clf_ruspini.predict(X_ruspini)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #   X   Y  CLASS\n",
       "0    1   4  53      1\n",
       "1    2   5  63      1\n",
       "2    3  10  59      1\n",
       "3    4   9  77      1\n",
       "4    5  13  49      1\n",
       "..  ..  ..  ..    ...\n",
       "70  71  66  23      4\n",
       "71  72  61  25      4\n",
       "72  73  76  27      4\n",
       "73  74  72  31      4\n",
       "74  75  64  30      4\n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Lakukan analisa mengapa pada XOR tidak bisa memperoleh score 1.0 (akurasi 100%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi logika XOR (Exclusive OR) tidak memiliki skor 1.0 pada model Perceptron karena sifatnya yang tidak linearly separable, atau dengan kata lain, data XOR tidak dapat dipisahkan oleh garis lurus dalam ruang dua dimensi.\n",
    "\n",
    "### Mengapa XOR Tidak Linearly Separable?\n",
    "\n",
    "Mari kita lihat tabel kebenaran untuk operasi XOR:\n",
    "\n",
    "| Input A | Input B | Output XOR |\n",
    "|---------|---------|------------|\n",
    "|    0    |    0    |      0     |\n",
    "|    0    |    1    |      1     |\n",
    "|    1    |    0    |      1     |\n",
    "|    1    |    1    |      0     |\n",
    "\n",
    "Jika kita plot data ini dalam ruang dua dimensi, dengan `Input A` di sumbu X dan `Input B` di sumbu Y, serta output di sumbu Z:\n",
    "\n",
    "- Titik (0, 0) dan (1, 1) memiliki output 0.\n",
    "- Titik (0, 1) dan (1, 0) memiliki output 1.\n",
    "\n",
    "Grafik ini membentuk pola di mana kita tidak dapat menggambar satu garis lurus yang bisa memisahkan titik-titik dengan output 0 dari titik-titik dengan output 1. Inilah yang dimaksud dengan *non-linearly separable*.\n",
    "\n",
    "### Keterbatasan Perceptron\n",
    "\n",
    "Perceptron adalah algoritma klasifikasi linear. Ini berarti perceptron hanya mampu memisahkan data yang dapat dipisahkan dengan garis lurus. Karena dataset XOR tidak bisa dipisahkan oleh garis lurus (karena poin yang dihasilkan tidak dapat dipisahkan dengan satu garis lurus), Perceptron tidak akan pernah mencapai akurasi 100% pada dataset XOR.\n",
    "\n",
    "### Output yang Mungkin untuk XOR dengan Perceptron\n",
    "\n",
    "Ketika kita melatih Perceptron dengan data XOR, kemungkinan besar model tidak akan memprediksi dengan benar semua kombinasi input, karena tidak bisa memisahkan dengan sempurna antara kelas 0 dan 1. Oleh karena itu, nilai `clf.score(data, label)` akan kurang dari 1.0, dan prediksi yang dihasilkan oleh `clf.predict(data)` mungkin akan memiliki beberapa kesalahan, misalnya `[0, 1, 1, 0]` atau pola lain yang tidak sepenuhnya benar.\n",
    "\n",
    "### Kesimpulan\n",
    "\n",
    "Untuk mempelajari fungsi XOR, kita memerlukan model yang lebih kompleks daripada Perceptron. Model seperti jaringan saraf dengan lebih dari satu lapisan (multilayer perceptron) bisa menangani masalah ini karena dapat mempelajari batas keputusan yang tidak linier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Carilah parameter yang tepat hingga error paling minimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('data/XOR.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Create MLP model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=10000, random_state=0)\n",
    "mlp.fit(data, label)\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"\\nAccuracy: {mlp.score(data, label)}\")\n",
    "print(f\"Predictions: {mlp.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dataset = pd.read_csv('data/XOR.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Create SVM model with RBF kernel\n",
    "svm = SVC(kernel='rbf', gamma='auto', random_state=0)\n",
    "svm.fit(data, label)\n",
    "\n",
    "# Evaluate model\n",
    "print(f\"\\nAccuracy: {svm.score(data, label)}\")\n",
    "print(f\"Predictions: {svm.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Dataset\n",
      "   X1  X2  Y\n",
      "0   0   0  0\n",
      "1   0   1  1\n",
      "2   1   0  1\n",
      "3   1   1  0\n",
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/XOR.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Add non-linear feature and model percepton\n",
    "data['x1_x2'] = data.iloc[:, 0] * data.iloc[:, 1]\n",
    "clf = Perceptron(tol=1e-3, random_state=0, max_iter=10000)\n",
    "clf.fit(data, label)\n",
    "\n",
    "# Evaluasi model\n",
    "print(\"XOR Dataset\")\n",
    "print(dataset)\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Dataset\n",
      "   5.1  3.5  1.4   .2  0\n",
      "0  4.9  3.0  1.4  0.2  0\n",
      "1  4.7  3.2  1.3  0.2  0\n",
      "2  4.6  3.1  1.5  0.2  0\n",
      "\n",
      "Accuracy: 0.9194630872483222\n",
      "Predictions: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0 -1  0 -1 -1 -1 -1  0 -1 -1 -1 -1  0 -1 -1  0 -1 -1 -1 -1 -1  1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  0 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1\n",
      "  1  1  1  1  1  1  1  1 -1  1  1  1 -1 -1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/iris.csv')\n",
    "data = scaler.fit_transform(dataset.iloc[:, 0:-1])  \n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0, max_iter=1000)\n",
    "clf.fit(data, label)\n",
    "\n",
    "print(\"IRIS Dataset\")\n",
    "print(dataset.head(3))\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Dataset\n",
      "Training Accuracy: 0.8823529411764706\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Training Predictions: [ 0 -1 -1  1  0 -1  1 -1 -1 -1  1  0 -1  1  1  1 -1 -1 -1  1  1 -1 -1 -1\n",
      " -1  1 -1  0 -1 -1 -1 -1  1 -1 -1  0  0  1 -1  0  0 -1  0  1  1  0 -1  1\n",
      " -1 -1  1  1  1 -1  0 -1  1 -1  0  1  0  1  1  0  0  1  0  0  0 -1  1  1\n",
      " -1  0  0 -1 -1  0  0 -1  0  1 -1  1 -1  0  1  0  1  0 -1  1 -1  1  1 -1\n",
      " -1  1 -1  1  1 -1 -1  0 -1  1 -1  0 -1 -1 -1 -1  0  0  0  1 -1  1  0]\n",
      "Test Predictions: [-1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  0  0 -1 -1 -1  0\n",
      " -1 -1 -1  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Split data and labels\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Split data into training and test sets\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a pipeline that standardizes the data then applies Perceptron\n",
    "clf = make_pipeline(StandardScaler(), Perceptron(tol=1e-3, random_state=0, max_iter=1000, eta0=1.0, penalty='l2'))\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"IRIS Dataset\")\n",
    "print(f\"Training Accuracy: {clf.score(data_train, label_train)}\")\n",
    "print(f\"Test Accuracy: {clf.score(data_test, label_test)}\")\n",
    "print(f\"Training Predictions: {clf.predict(data_train)}\")\n",
    "print(f\"Test Predictions: {clf.predict(data_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUSPINI Dataset\n",
      "   #   X   Y  CLASS\n",
      "0  1   4  53      1\n",
      "1  2   5  63      1\n",
      "2  3  10  59      1\n",
      "\n",
      "Accuracy: 1.0\n",
      "Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/ruspini.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Create and train Perceptron model on entire dataset\n",
    "clf = make_pipeline(StandardScaler(), Perceptron(tol=1e-3, \n",
    "        random_state=0, max_iter=1000, eta0=0.1, penalty='l2'))\n",
    "clf.fit(data, label)\n",
    "\n",
    "print(\"RUSPINI Dataset\")\n",
    "print(dataset.head(3))\n",
    "print(f\"\\nAccuracy: {clf.score(data, label)}\")\n",
    "print(f\"Predictions: {clf.predict(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Lakukan testing untuk data testing dan tampilkan kurasinya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS Dataset\n",
      "Training Accuracy: 0.9664\n",
      "Test Accuracy: 0.8333\n",
      "\n",
      "Training Predictions: [ 0 -1 -1  1  0 -1  1 -1 -1  0  1  0 -1  1  1  1 -1 -1 -1  1  1 -1  1  1\n",
      " -1  1 -1  0 -1 -1 -1 -1  1 -1  1  0  0  1 -1  0  0 -1  0  1 -1  0 -1  1\n",
      " -1  0  1  1  1  1  0  0  1  1  0  1  0  1  1  0  0 -1  0  0  0 -1  1  1\n",
      "  0  0  0  1 -1  0  0 -1  0  1 -1  1 -1  0  1  0  1  0  0  1 -1  1  1 -1\n",
      " -1  1 -1  1  1 -1 -1  0 -1  1  1  0 -1 -1 -1 -1  0  0  0  1 -1  1  0]\n",
      "Test Predictions: [-1  1 -1 -1  0  1  1 -1 -1  1  0  0 -1  0  0 -1  1 -1  0  0 -1  0 -1  0\n",
      " -1 -1 -1  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/iris.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Split data and  Create a pipeline\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.2, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(), Perceptron(tol=1e-3, random_state=0, max_iter=1000, eta0=0.1, penalty='l2'))\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# Predict and evaluate on training data and test data\n",
    "train_predictions = clf.predict(data_train)\n",
    "train_accuracy = accuracy_score(label_train, train_predictions)\n",
    "test_predictions = clf.predict(data_test)\n",
    "test_accuracy = accuracy_score(label_test, test_predictions)\n",
    "\n",
    "# Output the evaluation results\n",
    "print(\"IRIS Dataset\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"\\nTraining Predictions: {train_predictions}\")\n",
    "print(f\"Test Predictions: {test_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruspini Dataset\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Training Predictions: [4 2 3 4 3 1 3 4 1 4 3 1 3 4 1 2 1 4 1 2 3 3 1 2 4 1 3 1 2 4 2 1 1 4 1 1 3\n",
      " 1 3 2 4 1 1 2 3 1 2 3 2 3 3 1 2 2 1 4 4 4 3 3]\n",
      "Test Predictions: [3 3 2 4 2 2 4 3 2 1 3 3 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/ruspini.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Split data into training and test sets\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.2, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(), Perceptron(tol=1e-3,random_state=0, max_iter=1000, eta0=0.1, penalty='l2'))\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# Evaluate model on training and test data\n",
    "print(\"Ruspini Dataset\")\n",
    "print(f\"Training Accuracy: {clf.score(data_train, label_train)}\")\n",
    "print(f\"Test Accuracy: {clf.score(data_test, label_test)}\")\n",
    "print(f\"\\nTraining Predictions: {clf.predict(data_train)}\")\n",
    "print(f\"Test Predictions: {clf.predict(data_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIGIT Dataset\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.1875\n",
      "\n",
      "Training Predictions: [0 2 0 3 5 4 5 9 6 2 7 7 0 7 9 0 4 6 3 1 7 2 1 3 5 7 0 4 9 1 6 2 3 6 3 4 2\n",
      " 0 9 1 0 7 2 6 2 9 1 1 3 4 5 4 8 7 1 8 4 2 1 9 8 8 5 5]\n",
      "Test Predictions: [6 8 9 5 5 6 9 3 0 9 8 7 4 8 3 3]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/digit.csv')\n",
    "data = dataset.iloc[:, 0:-1]\n",
    "label = dataset.iloc[:, -1]\n",
    "\n",
    "# Split data into training and test sets\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, \n",
    "                label, test_size=0.2, random_state=0)\n",
    "clf = make_pipeline(StandardScaler(), Perceptron(tol=1e-3,random_state=0, \n",
    "                max_iter=1000, eta0=0.1, penalty='l2'))\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# Evaluate model on training and test data\n",
    "print(\"DIGIT Dataset\")\n",
    "print(f\"Training Accuracy: {clf.score(data_train, label_train)}\")\n",
    "print(f\"Test Accuracy: {clf.score(data_test, label_test)}\")\n",
    "print(f\"\\nTraining Predictions: {clf.predict(data_train)}\")\n",
    "print(f\"Test Predictions: {clf.predict(data_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
